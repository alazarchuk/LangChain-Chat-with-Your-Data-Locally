# LangChain: Chat with Your Data Locally
Data and notebooks from https://learn.deeplearning.ai/langchain-chat-with-your-data. But llama.cpp is used to do inference locally instead of OpenAI.
