# LangChain: Chat with Your Data Locally
Data and notebooks from https://learn.deeplearning.ai/langchain-chat-with-your-data. But instead of OpenAI llama.cpp is used to do inference locally.
